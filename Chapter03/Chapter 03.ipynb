{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752eabe1",
   "metadata": {},
   "source": [
    "# Chapter 3\n",
    "## It starts with a tensor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03b5faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f231a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14abed7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a792144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b461d6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(6)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3501a145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4581df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69cf9277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0518a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3560b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3, 2)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f7207a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bda346d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb81a137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c501cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a543af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bbb9f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51e92699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0891e+00,  1.0998e-01, -1.6473e-01,  1.6915e-01,  1.6928e+00],\n",
       "         [ 2.0190e-01,  1.0554e+00,  9.2402e-01,  5.4782e-01, -2.3978e-01],\n",
       "         [ 3.4687e-01,  2.7154e+00, -1.6360e+00, -1.7215e+00,  1.2798e+00],\n",
       "         [ 2.2138e+00, -8.1591e-01, -9.4237e-01, -1.8560e-01,  1.5802e+00],\n",
       "         [-8.5163e-01,  5.5462e-02,  9.1147e-01,  1.1983e+00, -4.3291e-01]],\n",
       "\n",
       "        [[ 9.4425e-01,  1.7668e-01,  4.1391e-01, -3.2979e-01, -3.8178e-01],\n",
       "         [ 2.4035e-01, -3.6148e-01, -9.0953e-01, -1.6758e+00,  1.8637e-01],\n",
       "         [ 6.0550e-01, -5.3467e-01,  2.9378e-01, -1.2064e+00, -6.8194e-01],\n",
       "         [ 2.6642e-01,  1.3116e+00, -7.8602e-01, -1.0812e+00,  1.0458e+00],\n",
       "         [-5.9584e-01,  7.0755e-01, -1.3706e+00,  1.1197e+00,  5.4598e-01]],\n",
       "\n",
       "        [[-2.6963e-01, -2.0932e-01, -6.3555e-01, -1.3598e-01, -1.5521e+00],\n",
       "         [-1.2236e+00, -1.4023e+00, -3.9979e-01, -8.1134e-01,  2.0407e+00],\n",
       "         [ 4.3554e-02,  2.0258e-01,  9.9905e-01,  9.8814e-02,  2.2964e+00],\n",
       "         [ 4.7658e-01,  1.4376e+00,  3.1190e-01,  3.1512e-01, -5.1513e-01],\n",
       "         [ 2.8844e-01, -6.0322e-01,  1.8321e+00,  2.5284e-03, -4.7699e-01]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5)\n",
    "img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4babf8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3762ac9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4388, -0.8897, -0.8319, -0.2056, -0.0808],\n",
       "          [ 0.4460, -0.1692, -0.6089, -0.5145,  0.2354],\n",
       "          [-0.4781, -0.4112,  1.0263,  1.1938, -0.0287],\n",
       "          [-0.2490,  0.5831,  0.5137,  0.3645, -0.8698],\n",
       "          [-1.2519, -0.8371,  0.9993,  0.6977,  0.4451]],\n",
       "\n",
       "         [[ 1.2600,  0.2066,  0.3616, -1.9593, -2.6945],\n",
       "          [ 0.1349, -1.1773, -0.2606,  1.4781,  0.0767],\n",
       "          [ 0.8998,  0.3224,  0.1400,  1.4978, -0.0186],\n",
       "          [ 1.2660, -0.4113,  0.5201,  1.7532, -1.1175],\n",
       "          [-1.2847, -0.0649, -1.1305,  0.7018, -0.9412]],\n",
       "\n",
       "         [[ 0.2382,  0.3988, -0.4904, -0.4685,  1.4866],\n",
       "          [-0.4698,  2.1554, -2.1341, -1.0899, -0.9437],\n",
       "          [-0.4153,  1.0197,  1.1454,  0.1676,  1.1651],\n",
       "          [-0.6052, -0.7761,  0.4153, -2.2237,  0.0571],\n",
       "          [-1.3267,  1.6835, -0.1467, -1.2505, -0.5998]]],\n",
       "\n",
       "\n",
       "        [[[-0.7372, -0.4552, -1.2940,  1.3815,  0.7857],\n",
       "          [-0.4220, -1.4880,  0.6428, -2.6303, -0.1236],\n",
       "          [ 0.2118,  0.8421,  0.3888, -0.8136, -0.6694],\n",
       "          [ 0.9029, -0.7989,  0.4731,  1.1113,  0.4225],\n",
       "          [ 0.3621,  1.8047, -0.3131, -1.1297, -1.0450]],\n",
       "\n",
       "         [[-0.6916, -0.3098,  0.9376,  0.7846,  0.0830],\n",
       "          [ 0.2441, -0.3125, -2.2573, -0.3424, -2.0767],\n",
       "          [-0.3570,  0.3773,  0.4408,  0.4037,  0.0769],\n",
       "          [ 0.4460, -0.5409, -1.0022,  1.2118, -0.0466],\n",
       "          [-0.0774, -1.0943,  2.8411, -1.7924, -0.7593]],\n",
       "\n",
       "         [[-0.4655, -0.7638,  0.7325,  0.9520,  0.9466],\n",
       "          [-0.2595, -0.4457,  1.1257, -0.3674,  0.9444],\n",
       "          [ 0.5733,  1.3006, -0.2388, -0.1459,  0.3818],\n",
       "          [-0.0484,  1.1825,  1.3366, -2.1550,  0.1475],\n",
       "          [ 0.4886, -0.4190,  1.2331, -0.6432, -1.8444]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5)\n",
    "batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0704264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "695cac4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1ff2644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2126],\n",
       "        [0.7152],\n",
       "        [0.0722]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ebacb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2126]],\n",
       "\n",
       "        [[0.7152]],\n",
       "\n",
       "        [[0.0722]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights.unsqueeze_(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b163586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.unsqueeze(-1).unsqueeze_(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bf7ecdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e058a724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6ba70ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24108/2371314847.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1900.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c5b0ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b67c2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0ddbcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4243,  0.1346,  0.2151, -0.2097, -0.0252],\n",
       "         [ 0.1265, -0.1354, -0.4829, -1.1406,  0.2297],\n",
       "         [ 0.5099,  0.2095, -0.0656, -1.2217, -0.0498],\n",
       "         [ 0.6956,  0.8684, -0.7400, -0.7900,  1.0467],\n",
       "         [-0.5864,  0.4743, -0.6542,  1.0557,  0.2640]],\n",
       "        names=('rows', 'columns')),\n",
       " torch.Size([5, 5]),\n",
       " ('rows', 'columns'))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named, gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e77f973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4243,  0.1346,  0.2151, -0.2097, -0.0252],\n",
       "         [ 0.1265, -0.1354, -0.4829, -1.1406,  0.2297],\n",
       "         [ 0.5099,  0.2095, -0.0656, -1.2217, -0.0498],\n",
       "         [ 0.6956,  0.8684, -0.7400, -0.7900,  1.0467],\n",
       "         [-0.5864,  0.4743, -0.6542,  1.0557,  0.2640]]),\n",
       " torch.Size([5, 5]),\n",
       " (None, None))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain, gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda147e7",
   "metadata": {},
   "source": [
    "### dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a530283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int16, torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)\n",
    "short_points.dtype, double_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31e89e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int16, torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()\n",
    "short_points.dtype, double_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e1fe4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int16, torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "short_points = torch.ones(10, 2).to(dtype=torch.short)\n",
    "short_points.dtype, double_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0390d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When mixing input types in operations, the inputs are converted to the larger type automatically.\n",
    "points_64 = torch.rand(5, dtype=torch.double)\n",
    "points_short = points_64.to(torch.short)\n",
    "points_64 * points_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2a63588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " torch.Size([3, 2]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a_t = torch.transpose(a, 0, 1) # or a_t = a.transpose(0, 1)\n",
    "a, a_t, a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b478614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24108/2923139482.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  points.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7049481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 2.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "points_storage[0], points_storage[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d40a6741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_storage = points.storage()\n",
    "points_storage[0] = 2.0\n",
    "points # first element is changed from 4 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d69f332b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# methods that have _ at the end of them are inplace like squeeze_ and zero_\n",
    "a = torch.ones(3, 2)\n",
    "a.zero_()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ddc816c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12b31993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8001dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "391dc550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2aae6a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point[0] = 10.0\n",
    "points # 5 changed to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0221fbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1].clone()\n",
    "second_point[0] = 10.0\n",
    "points # 5 is not changed to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a242abb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose:\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "526da752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad5ff5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc3d9d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (1, 2))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride(), points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "490a5429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]), torch.Size([5, 4, 3]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "some_t.shape, transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ee759e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 5, 1), (1, 5, 20))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride(), transpose_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "edeac1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#contigous tensor:\n",
    "points.is_contiguous(), points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3a52c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9203dc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ccdc7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "832db168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf45e936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41f98595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 5.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d79ef09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d8ba45bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = points.to(device='cuda')\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "adbe0b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = points.to(device='cuda:0')\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b8463b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = 2 * points #CPU\n",
    "points_gpu = 2 * points.to(device='cuda') #GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87aa272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points_gpu + 4 #still gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e92eac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_cpu = points_gpu.to(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4910d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.cuda()\n",
    "points_gpu = points.cuda(0)\n",
    "points_cpu = points_gpu.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9528d99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a8965e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.from_numpy(points_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e96b2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points, '../data/ourpoints.t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0df862e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ourpoints.t','wb') as f:\n",
    "    torch.save(points, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b12647ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.load('../data/ourpoints.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ec34bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ourpoints.t','rb') as f:\n",
    "    points = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd67eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('../data/ourpoints.hdf5', 'w')\n",
    "dset = f.create_dataset('coords', data=points.numpy())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d092dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('../data/ourpoints.hdf5', 'r')\n",
    "dset = f['coords']\n",
    "last_points = dset[-2:]\n",
    "last_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "80456e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_points = torch.from_numpy(dset[-2:])\n",
    "f.close()\n",
    "last_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59eacdd",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "714fca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor a from list(range(9)). Predict and then check the size, offset, and stride.\n",
    "tens = torch.tensor(range(9))\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "71c98ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), torch.Size([9]), torch.Size([9]), 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.stride(), tens.shape, tens.size(), tens.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a7918abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new tensor using b = a.view(3, 3). What does view do? Check that a and b share the same storage.\n",
    "tens_b = tens.view(3, 3)\n",
    "tens_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f40d8943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(tens_b.storage()) == id(tens.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "71a4c2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1), torch.Size([2, 2]), torch.Size([2, 2]), 4)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_c = tens_b[1:,1:]\n",
    "tens_c.stride(), tens_c.shape, tens_c.size(), tens_c.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e1432ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mcos(tens_b)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.math.cos(tens_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "41624d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.5403, -0.4161],\n",
       "        [-0.9900, -0.6536,  0.2837],\n",
       "        [ 0.9602,  0.7539, -0.1455]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(tens_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ea459bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ccb0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens_b = tens_b.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c767de8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb61d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
